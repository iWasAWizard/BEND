# BEND/docker-compose.ollama.yml
version: "3.9"

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: unless-stopped
    environment:
      # Service configuration
      - OLLAMA_HOST=${OLLAMA_HOST:-"0.0.0.0"}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      - OLLAMA_API_KEY=${BEND_API_KEY}
      # Model configuration
      - OLLAMA_DEFAULT_MODEL=${MODEL_NAME:-"hf.co/TheBloke/Mistral-7B-OpenOrca-GGUF:Q4_K_M"}
      - OLLAMA_CONTEXT_LEN=${MODEL_CONTEXT_SIZE:-8192}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-3h}
      # Operational configuration
      - OLLAMA_LOG_LEVEL=${OLLAMA_LOG_LEVEL:-"warning"}
      - OLLAMA_FLASH_ATTENTION=${OLLAMA_FLASH_ATTENTION:-1}
      - OLLAMA_KV_CACHE_TYPE=${OLLAMA_KV_CACHE_TYPE:-q8_0}
    command: >
      serve & sleep 2 && ollama run ${MODEL_NAME:-'hf.co/TheBloke/Mistral-7B-OpenOrca-GGUF:Q4_K_M'} ""
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    networks:
      - bend-net

volumes:
  ollama_data: