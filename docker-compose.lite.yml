# BEND/docker-compose.lite.yml
# A lightweight configuration that runs only the essential BEND services
# for powering an autonomous agent like AEGIS.
# Use with the --lite flag and a profile name, e.g., `manage.sh up --lite vllm`

networks:
  bend-net:
    driver: bridge

services:
  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_PORT:-12006}:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - bend-net

  retriever:
    build:
      context: ./rag
    container_name: retriever
    restart: unless-stopped
    ports:
      - "${RETRIEVER_PORT:-12007}:8000"
    depends_on:
      - qdrant
    volumes:
      - ./rag/docs:/app/docs
    environment:
      - BEND_API_KEY=${BEND_API_KEY}
      - OTEL_SERVICE_NAME=retriever
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
    networks:
      - bend-net

  ollama:
    profiles: ["ollama"]
    image: ollama/ollama
    container_name: ollama
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT:-12009}:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - bend-net

  redis:
    image: redis/redis-stack:latest
    container_name: redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-12010}:6379"
    networks:
      - bend-net

  vllm:
    profiles: ["vllm"]
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: unless-stopped
    ports:
      - "${VLLM_PORT:-12011}:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./models:/root/.cache/huggingface/hub
    command: >
      --model ${MODEL_NAME}
      --served-model-name aegis-agent-model
      --enforce-eager
      --device cpu
      --gpu-memory-utilization ${VLLM_GPU_MEMORY_UTILIZATION:-0.90}
    networks:
      - bend-net

volumes:
  qdrant_data:
  ollama_data: