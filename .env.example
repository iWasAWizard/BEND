# ===================================================
# == BEND .env
# ===================================================
# This file is a template for configuring the BEND stack.
# Copy this to .env and edit as needed. Some variables are set automatically
# by the management scripts.

# --- Core Model Configuration (Managed by scripts/switch-model.sh) ---
# The filename of the GGUF model inside the ./models directory for KoboldCPP to use.
# This is set by 'switch-model.sh'.
MODEL_NAME=

# The context size (in tokens) for the selected KoboldCPP model.
# This is set by 'switch-model.sh'.
MODEL_CONTEXT_SIZE=8192

# --- LLM Backend Configuration (Managed by scripts/switch-backend.sh) ---
# Determines which LLM service to run. Can be 'koboldcpp', 'ollama', or 'exl2'.
# This is set by 'switch-backend.sh'.
BEND_LLM_BACKEND=

# The internal URL for the active LLM's OpenAI-compatible API.
# This tells OpenWebUI which service to connect to.
# This is set by 'switch-backend.sh'.
OLLM_API_BASE_URL=

# Ollama service configuration
OLLAMA_HOST="0.0.0.0"
OLLAMA_KEEP_ALIVE=3h
OLLAMA_FLASH_ATTENTION=1
OLLAMA_LOG_LEVEL=info
OLLAMA_KV_CACHE_TYPE=q8_0

# --- GPU & Performance Tuning ---
# Number of model layers to offload to the GPU for KoboldCPP. High value (e.g., 99) means max.
KOBOLD_GPU_LAYERS=0
# Number of CPU threads for KoboldCPP to use for inference.
KOBOLD_THREADS=16
# Number of model layers to offload to the GPU for Whisper.
WHISPER_GPU_LAYERS=0

# --- Service Configuration ---
# The TTS voice model for Piper to use.
PIPER_VOICE=en_US-lessac-medium
# The GGML model file for Whisper to use.
WHISPER_MODEL_NAME=ggml-small.en.bin

# --- Port Configuration ---
# Change these if you have port conflicts on your host machine.
OPENWEBUI_PORT=12002
WHISPER_PORT=12003
PIPER_PORT=12004
GLANCES_PORT=12005
QDRANT_PORT=12006
RETRIEVER_PORT=12007
VOICEPROXY_PORT=12008
KOBOLD_PORT=12009
OLLAMA_PORT=11434
EXL2_PORT=12010

# --- Security & Observability (Optional) ---
# An optional API key to secure the Voice Proxy and Retriever endpoints.
# If set, this same key must be provided by clients (like AEGIS).
BEND_API_KEY=

# The endpoint for OpenTelemetry tracing data (e.g., http://jaeger:4317).
OTEL_EXPORTER_OTLP_ENDPOINT=

# The port on the AEGIS agent container to send network logs to.
AEGIS_LOG_PORT=9002

# --- Hugging Face Token (Optional) ---
# To download gated models, you need a Hugging Face token with "read" permissions.
HF_TOKEN=