# BEND/.env.example
# Example environment variables for the BEND stack.
# Copy this file to .env and fill in the values.
# The `switch-model.sh` script will populate the model-related variables automatically.

# --- Model Configuration ---
# The Hugging Face repository ID for the model vLLM will serve.
MODEL_NAME=NousResearch/Nous-Hermes-2-Mistral-7B-DPO
# The specific .gguf filename for the KoboldCPP service to use.
KOBOLDCPP_MODEL_NAME=Nous-Hermes-2-Mistral-7B-DPO-GGUF.Q4_K_M.gguf
# The context size for the model.
MODEL_CONTEXT_SIZE=16384
# (Optional) For downloading gated models from Hugging Face.
# HF_TOKEN=hf_...

# --- GPU Configuration ---
# Percentage of GPU memory to use for the vLLM model.
VLLM_GPU_MEMORY_UTILIZATION=0.90
# Number of layers to offload to the GPU for KoboldCPP (GGUF models).
KOBOLD_GPU_LAYERS=50
# Number of layers to offload to the GPU for Whisper.
WHISPER_GPU_LAYERS=99

# --- Service Configuration ---
# The OpenAI-compatible endpoint URL for OpenWebUI to connect to.
# This should point to your primary LLM service (vLLM or KoboldCPP).
OLLM_API_BASE_URL=http://vllm:8000/v1
# A secret key to protect the BEND API endpoints (retriever, voiceproxy).
BEND_API_KEY=a-secret-key-for-bend