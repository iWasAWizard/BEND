# BEND/docker-compose.yml
networks:
  bend-net:
    driver: bridge

services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    restart: unless-stopped
    ports:
      - "${OPENWEBUI_PORT:-12002}:3000"
    environment:
      - OLLM_API_BASE_URL=${OLLM_API_BASE_URL}
      - WEBUI_URL=http://localhost:12002
      - PORT=3000
      - ENABLE_PERSISTENT_CONFIG=true
    volumes:
      - openwebui_data:/app/backend/data
    networks:
      - bend-net

  whisper:
    build:
      context: .
      dockerfile: Dockerfile.build-services
      target: whisper-builder
      args:
        - GPU_ENABLED=${WHISPER_GPU_ENABLED:-false}
    container_name: whisper
    restart: unless-stopped
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=${TIMEZONE:-America/New_York}
      - WHISPER_MODEL=${WHISPER_MODEL:-small.en}
    command: >
      /app/build/bin/whisper-server
      --model /app/models/ggml-${WHISPER_MODEL}.bin
      --threads 4
      --host 0.0.0.0
      --port 9000
      --convert
      --no-gpu
      --flash-attn
    volumes:
      - whisper_data:/config
    ports:
      - "${WHISPER_PORT:-12003}:9000"
    networks:
      - bend-net

  piper:
    build:
      context: .
      dockerfile: Dockerfile.piper
    container_name: piper
    restart: unless-stopped
    environment:
      - LD_LIBRARY_PATH=./piper
    command: >
      python3 -m piper.http_server
      --model /app/${PIPER_VOICE:-en_US-lessac-medium}.onnx
      --port 59125
      --host 0.0.0.0
    ports:
      - "${PIPER_PORT:-12004}:59125"
    networks:
      - bend-net

  glances:
    image: nicolargo/glances:latest
    container_name: glances
    restart: unless-stopped
    ports:
      - "${GLANCES_PORT:-12005}:61208"
    pid: "host"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - GLANCES_OPT=-w
    networks:
      - bend-net

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_PORT:-12006}:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - bend-net

  retriever:
    build:
      context: ./rag
    container_name: retriever
    restart: unless-stopped
    ports:
      - "${RETRIEVER_PORT:-12007}:8000"
    depends_on:
      - qdrant
    volumes:
      - ./rag/docs:/app/docs
    environment:
      - BEND_API_KEY=${BEND_API_KEY}
      - OTEL_SERVICE_NAME=retriever
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
    networks:
      - bend-net

  voiceproxy:
    build: ./voice-proxy
    container_name: voiceproxy
    restart: unless-stopped
    ports:
      - "${VOICEPROXY_PORT:-12008}:8001"
    depends_on:
      - whisper
      - piper
    environment:
      - BEND_API_KEY=${BEND_API_KEY}
      - OTEL_SERVICE_NAME=voiceproxy
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
    networks:
      - bend-net

  koboldcpp:
    build:
      context: .
      dockerfile: Dockerfile.build-services
      target: kobold-builder
      args:
        - GPU_ENABLED=${KOBOLD_GPU_ENABLED:-false}
    container_name: koboldcpp
    restart: unless-stopped
    ports:
      - "${KOBOLD_PORT:-12009}:5001"
    volumes:
      - ./models:/models
    command: >
      python3 koboldcpp.py
      --model /models/${KOBOLDCPP_MODEL_NAME}
      --host 0.0.0.0
      --port 5001
      --threads ${KOBOLD_THREADS:-16}
      --contextsize ${MODEL_CONTEXT_SIZE}
      --gpulayers ${KOBOLD_GPU_LAYERS:-0}
      --smartcontext
      --usemlock
    networks:
      - bend-net

  redis:
    image: redis/redis-stack:latest
    container_name: redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-12010}:6379"
    networks:
      - bend-net

  vllm:
    image: openeuler/vllm-cpu:latest
    container_name: vllm
    restart: unless-stopped
    ports:
      - "${VLLM_PORT:-12011}:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./models:/root/.cache/huggingface/hub
    command: >
      --model ${MODEL_NAME}
      --served-model-name aegis-agent-model
      --enforce-eager
      --device cpu
      --gpu-memory-utilization ${VLLM_GPU_MEMORY_UTILIZATION:-0.90}
    networks:
      - bend-net

  nemoguardrails:
    build:
      context: .
      dockerfile: Dockerfile.nemo
    container_name: nemoguardrails
    restart: unless-stopped
    ports:
      - "${GUARDRAILS_PORT:-12013}:8000"
    networks:
      - bend-net

volumes:
  qdrant_data:
  openwebui_data:
  whisper_data: