version: "3.9"

networks:
  bend-net:
    driver: bridge

services:
  koboldcpp:
    build:
      context: .
      dockerfile: Dockerfile.build-services
      target: kobold-builder
      args:
        - GPU_ENABLED=${KOBOLD_GPU_ENABLED:-false}
    container_name: koboldcpp
    restart: unless-stopped
    ports:
      - "${KOBOLD_PORT:-12009}:5001"
    volumes:
      - ./models:/models
    command: >
      python3 koboldcpp.py
      --model /models/${MODEL_NAME}
      --host 0.0.0.0
      --port 5001
      --threads ${KOBOLD_THREADS:-16}
      --contextsize ${MODEL_CONTEXT_SIZE}
      --gpulayers ${KOBOLD_GPU_LAYERS:-0}
    networks:
      - bend-net

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    restart: unless-stopped
    ports:
      - "${OPENWEBUI_PORT:-12002}:3000"
    environment:
      # Use the OpenAI-compatible endpoint for OpenWebUI
      - OPENAI_API_BASE_URL=http://koboldcpp:5001/v1
    depends_on:
      - koboldcpp
    networks:
      - bend-net
    profiles:
      - "full"

  whisper:
    build:
      context: .
      dockerfile: Dockerfile.build-services
      target: whisper-builder
      args:
        - GPU_ENABLED=${WHISPER_GPU_ENABLED:-false}
    container_name: whisper
    restart: unless-stopped
    command: >
      ./build/bin/whisper-server
      -m ./models/${WHISPER_MODEL_NAME:-ggml-small.en.bin}
      --host 0.0.0.0
      --port 9000
      --no-gpu
      --convert
    ports:
      - "${WHISPER_PORT:-12003}:9000"
    networks:
      - bend-net
    profiles:
      - "full"

  piper:
    build:
      context: .
      dockerfile: Dockerfile.piper
    container_name: piper
    restart: unless-stopped
    command: "./piper/piper --model /data/${PIPER_VOICE:-en_US-lessac-medium.onnx} --port 59125 --host 0.0.0.0"
    ports:
      - "${PIPER_PORT:-12004}:59125"
    volumes:
      - ./piper:/data
    networks:
      - bend-net
    profiles:
      - "full"

  glances:
    image: nicolargo/glances:latest
    container_name: glances
    restart: unless-stopped
    ports:
      - "${GLANCES_PORT:-12005}:61208"
    pid: "host"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - GLANCES_OPT=-w
    networks:
      - bend-net
    profiles:
      - "full"

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_PORT:-12006}:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - bend-net
    profiles:
      - "full"

  retriever:
    build:
      context: ./rag
    container_name: retriever
    restart: unless-stopped
    ports:
      - "${RETRIEVER_PORT:-12007}:8000"
    depends_on:
      - qdrant
    volumes:
      - ./rag/docs:/app/docs
    environment:
      - BEND_API_KEY=${BEND_API_KEY}
      - OTEL_SERVICE_NAME=retriever
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
    networks:
      - bend-net
    profiles:
      - "full"

  voiceproxy:
    build: ./voice-proxy
    container_name: voiceproxy
    restart: unless-stopped
    ports:
      - "${VOICEPROXY_PORT:-12008}:8001"
    depends_on:
      - whisper
      - piper
    environment:
      - BEND_API_KEY=${BEND_API_KEY}
      - OTEL_SERVICE_NAME=voiceproxy
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
    networks:
      - bend-net
    profiles:
      - "full"

volumes:
  qdrant_data:
